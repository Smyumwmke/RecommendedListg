深入浅出强化学习:原理入门 PDF下载 郭宪 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712132918
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712132918
<p>书名:深入浅出强化学习:原理入门</p><p>作者:郭宪</p><p>页数:239</p><p>定价:¥79.0</p><p>出版社:电子工业出版社</p><p>出版日期:2018-01-01</p><p>ISBN:9787121329180</p><p><h2>相关资料</h2></p>[<p>推荐序一
强化学习是机器学习的一个重要分支，它试图解决决策优化的问题。所谓决策优化，是指面对特定状态（State，S），采取什么行动方案（Action，A），才能使收益*（Reward，R）。很多问题都与决策优化有关，比如下棋、投资、课程安排、驾车，动作模仿等。
AlphaGo的核心算法，就是强化学习。AlphaGo不仅稳操胜券地战胜了当今世界所有人类高手，而且甚至不需要学习人类棋手的棋谱，完全靠自己摸索，就在短短几天内，发现并超越了一千多年来人类积累的全部围棋战略战术。
*简单的强化学习的数学模型，是马尔科夫决策过程（Markov Decision Process，MDP）。之所以说MDP是一个简单的模型，是因为它对问题做了很多限制。
1．面对的状态st，数量是有限的。
2．采取的行动方案at，数量也是有限的。
3．对应于特定状态st，当下的收益rt是明确的。
4．在某一个时刻t，采取了行动方案at，状态从当前的st转换成下一个状态st 1。下一个状态有多种可能，记为 , i =
1... n。
换句话说，面对局面st，采取行动at，下一个状态是
，不是确定的，而是概率的，状态转换概率，记为P( | st, at )。但是状态转换只依赖于当前状态st，而与先前的状态st-1, st-2 ...无关。
解决马尔科夫决策过程问题的常用的算法，是动态规划（Dynamic Programming）。
对马尔科夫决策过程的各项限制，不断放松，研究相应的算法，是强化学习的目标。例如对状态st放松限制：
1．假如状态st的数量，虽然有限，但是数量巨大，如何降低动态规划算法的计算成本；
2．假如状态st的数量是无限的，现有动态规划算法失效，如何改进算法；
3．假如状态st的数量不仅是无限的，而且取值不是离散的，而是连续的，如何改进算法；
4．假如状态st不能被完全观察到，只能被部分观察到，剩余部分被遮挡或缺失，如何改进算法；
5．假如状态st完全不能被观察到，只能通过其他现象猜测潜在的状态，如何改进算法。
放松限制，就是提升问题难度。在很多情况下，强化学习的目标，不是寻找*的*解，而是寻找相对满意的次优解。
强化学习的演进，有两个轴线：一个是不断挑战更难的问题，不断从次优解向*解逼近；另一个是在不严重影响算法精度的前提下，不断降低算法的计算成本。
此书的叙述线索非常清晰，从*简单的解决马尔科夫决策过程的动态规划算法，一路讲解到*前沿的深度强化学习算法（Deep Q Network，DQN），单刀直入，全无枝枝蔓蔓之感。不仅解释数学原理，而且注重编程实践。同时，行文深入浅出，通俗易懂。
将本书与Richard Sutton和Andrew Barto合著的经典著作Reinforcement Learning: An Introduction, Second Edition相比，Sutton和Barto在内容上更注重全面，覆盖了强化学习各个分支的研究成果；而本书更强调实用，是值得精读的教材。
邓侃
PhD of Robotics Institute, School of Computer Science, Carnegie
Mellon University，前Oracle 主任架构师、前百度网页搜索部高级总监、北京大数医达科技有限公司创始人
 
推荐序二
强化学习又称为增强学习或再励学习（Reinforcement learning），是AlphaGo、AlphaGo Zero等人工智能软件的核心技术。近年来，随着高性能计算、大数据和深度学习技术的突飞猛进，强化学习算法及其应用也得到更为广泛的关注和更加快速的发展。尤其是强化学习与深度学习相结合而发展起来的深度强化学习技术已经取得若干突破性进展。AlphaGo与人类*棋手之间的对弈，使得深度强化学习技术在学术界和工业界得到了更为广泛的关注。强化学习不仅在计算机博弈中取得巨大成功，而且在机器人控制、汽车智能驾驶、人机对话、过程优化决策与控制等领域，也被认为是实现高级人工智能*有潜力的方法。
本人在多年从事强化学习与近似动态规划理论和应用的研究过程中，力求不断提升强化学习算法的快速收敛性和泛化性能，并且将强化学习新理论和新算法应用于移动机器人和自主驾驶车辆等领域，为智能移动机器人和自主驾驶车辆在复杂、不确定条件下的自主优化决策和自学习控制提供高效的技术手段。今后，随着相关理论和技术的不断进步，强化学习技术在智能机器人和自主驾驶车辆、复杂生产过程的优化决策与控制、天空与海洋无人系统等领域的应用将很快会有新的突破。
强化学习的思想从20世纪初便被提出来了，经过将近一个世纪的发展，强化学习与心理学、运筹学、智能控制、优化理论、计算智能、认知科学等学科有着密切的联系，是一个典型的多学科交叉领域。来自不同学科的概念和思想使得初学者学习和了解强化学习存在较大的困难。郭宪博士和方勇纯教授的这本《深入浅出强化学习：原理入门》用通俗的语言系统地讲解了强化学习的基本概念以及它们之间的关联关系。从内容的广度来看，这本书涵盖了强化学习领域的基本概念和基本方法（基于值函数的方法和基于直接策略搜索的方法）；从内容的深度来看，这本书既有传统的强化学习算法（基于表格的强化学习方法，如Qlearning，Sarsa算法等），也有*近发展起来的深度强化学习算法（如DQN，TRPO，DDPG等）。另外，该书还有两大特色：*，在介绍强化学习算法的同时，相应地介绍了算法设计和分析的数学基础；第二，相关算法配有代码实例。这两个特色使得该书非常适合初学者、相关领域科研人员以及研究生学习和研讨。鉴于此，强烈推荐该书作为广大读者学习强化学习技术的入门读物，也希望该书能引导和帮助更多的学者投入到强化学习的研究和应用中，为我国新一代人工智能的发展贡献自己的力量。
徐昕
国防科技大学教授
 
推荐序三
继深度学习与大数据结合产生了巨大的技术红利之后，人们开始探索后深度学习时代的新技术方向。当前主流的机器学习范式大都是以预先收集或构造数据及标签，基于已存在的静态数据进行机器学习为特征的“开环学习”。近年来，采用动态的数据及标签，将数据产生与模型优化通过一定的交互方式结合在一起，将动态反馈信号引入学习过程的“闭环学习”受到越来越多的关注。强化学习就是“闭环学习”范式的典型代表。
在AlphaGo战胜人类围棋选手之后，AlphaGO
Zero以其完全凭借自我学习超越人类数千年经验的能力再次刷新了人类对人工智能的认识。而这一人工智能领域的巨大成功的核心就是强化学习与深度学习的结合，这也使得强化学习这一行为主义学习范式，受到了学术界和产业界的新一轮广泛关注。
本书的出版正是在这样的背景下，可谓恰逢其时。本书深入浅出地对强化学习的理论进行了综合全面的介绍，系统完整又通俗易懂。同时，结合OpenAI的仿真环境，将强化学习算法的实际使用与理论介绍联系起来，具有很强的实用性。在强化学习方法论得到广泛关注，以及其实践需求快速增长的背景下，这是一本很好的入门教程。
俞凯
上海交通大学研究员
 
推荐序四
AlphaGo的诞生掀起了（深度）强化学习技术的一轮热潮，该方向已成为人工智能领域*热门的方向之一，由于其通用性而备受各个应用领域推崇，从端对端控制、机器人手臂控制，到推荐系统、自然语言对话系统等。（深度）强化学习也被OpenAI等公司认为是实现通用人工智能的重要途径。
然而目前强化学习中文资料相对零散，缺少兼具系统性和前沿性的强化学习教学及科研资料。郭博士的《深入浅出强化学习：原理入门》这本书恰好填补了这一空白。本书根据郭博士在知乎的强化学习专栏内容整理而成，条分缕析、通俗易懂，既对强化学习基础知识做了全方面“深入浅出”的讲述，又涵盖了深度强化学习领域一系列*的前沿技术。因此它无论是对强化学习的入门者，还是强化学习领域研究人员和工程师，都是一本很好的推荐读物，相信不同的读者都会从中获益。
郝建业
天津大学副教授、天津市青年千人、天津大学“北洋青年学者”
 
推荐序五
受行为主义心理学研究启发，在机器学习领域中产生了一种交互式学习方法的分支，这便是强化学习，又称为增强学习。强化学习模拟的是人类的一种学习方式，在执行某个动作或决策后根据执行效果来获得奖励，通过不断与环境的交互进行学习，*终达到目标。强化学习概念早在上世纪就已经提出，在计算机领域，*个增强学习问题是利用奖惩手段学习迷宫策略。然而，直到2016年AlphaGo对决李世石一战成名后，强化学习的概念才真正广为人知。强化学习主要应用于众多带有交互性和决策性问题，比如博弈、游戏、机器人、人机对话等，这些问题是常用的监督学习和非监督学习方法无法很好处理的。
本人一直从事移动机器人、机器视觉和机器学习领域的研究，以及人工智能课程的教学。此前，为了解决人形机器人斜坡稳定行走问题，在查阅深度学习相关资料的过程中，在网上偶然看到郭宪博士开辟的强化学习专栏，读后很有收获。现在他将专栏文章整理编著成书，重新按知识层次进行编排和补充，对于读者学习更有帮助。
本书覆盖了强化学习*基本的概念和算法。在基于值函数的强化学习方法中，介绍了蒙特卡罗法、时间差分法和值函数逼近法。在基于直接策略搜索的强化学习方法中，介绍了策略梯度法、置信域策略法、确定性策略搜索法和引导策略搜索。在强化学习的前沿部分，介绍了逆向强化学习、深度强化学习和PILCO等。除了深度学习算法本身，书中还对涉及的基础知识，如概率学基础、马尔科夫决策过程、线性方程组的数值求解方法、函数逼近方法、信息论中熵和相对熵的概念等也做了详细的说明。本书非常适合科技人员、高等学校师生和感兴趣人员作为入门强化学习的读物，也可作为相关研究和教学的参考书。
本书内容深入浅出、文字简单明了，采用了丰富的实例，让读者易读、易懂。同时配有习题和代码详解，能有效提升读者对理论知识的理解，帮助读者运用理论解决实际问题。建议读者跟随书中的示例和代码（https://github.com/gxnk/reinforcement- learning-code）来实现和验证相关强化学习算法，并可同时关注作者的知乎专栏（https://zhuanlan.zhihu.com/sharerl）以便更好地互动和探讨相关细节。
陈白帆
中南大学副教授
湖南省自兴人工智能研究院副院长</p>]<p><h2>本书特色</h2></p>[<p>
《深入浅出强化学习：原理入门》用通俗易懂的语言深入浅出地介绍了强化学习的基本原理，覆盖了传统的强化学习基本方法和当前炙手可热的深度强化学习方法。开篇从*基本的马尔科夫决策过程入手，将强化学习问题纳入到严谨的数学框架中，接着阐述了解决此类问题*基本的方法——动态规划方法，并从中总结出解决强化学习问题的基本思路：交互迭代策略评估和策略改善。基于这个思路，分别介绍了基于值函数的强化学习方法和基于直接策略搜索的强化学习方法。*后介绍了逆向强化学习方法和近年具有代表性、比较前沿的强化学习方法。
除了系统地介绍基本理论，书中还介绍了相应的数学基础和编程实例。因此，《深入浅出强化学习：原理入门》既适合零基础的人员入门学习、也适合相关科研人员作为研究参考。
                                        </p>]<p><h2>内容简介</h2></p>[<p>从零起步掌握强化学习技术精髓，称霸人工智能领域！
《深入浅出强化学习：原理入门》针对初学者的需求，直接分析原理，并辅以编程实践。从解决问题的思路，层层剖析，普及了传统的强化学习基本方法和当前炙手可热的深度强化学习方法，直接将读者带入强化学习的殿堂。读完本书，读者能在熟练掌握原理的基础上，直接上手编程实践。
本书的叙述方式简洁、直接、清晰，值得精读！ </p>]<p><h2>作者简介</h2></p>[<p>郭宪，南开大学计算机与控制工程学院博士后。2009 年毕业于华中科技大学机械设计制造及自动化专业，同年保送到中国科学院沈阳自动化研究所硕博连读，主攻机器人动力学建模与控制，并于 2016 年 1 月获得工学博士学位；期间在国内外知名杂志和会议发表论文数 10 篇。2016 年以来，郭博士主攻方向为机器人智能感知和智能决策，目前主持两项国家级课题，内容涉及深度学习、深度强化学习等智能算法在机器人领域中的应用。</p>]<p><h2>目录</h2></p>
    1  绪论  1
1.1  这是一本什么书  1
1.2  强化学习可以解决什么问题  2
1.3  强化学习如何解决问题  4
1.4  强化学习算法分类及发展趋势  5
1.5  强化学习仿真环境构建  7
1.5.1  gym安装及简单的demo示例  8
1.5.2  深入剖析gym环境构建  10
1.6  本书主要内容及安排  12
**篇  强化学习基础  17
2  马尔科夫决策过程  18
2.1  马尔科夫决策过程理论讲解  18
2.2  MDP中的概率学基础讲解  26
2.3  基于gym的MDP实例讲解  29
2.4  习题  34
3  基于模型的动态规划方法  36
3.1  基于模型的动态规划方法理论  36
3.2  动态规划中的数学基础讲解  47
3.2.1  线性方程组的迭代解法  47
3.2.2  压缩映射证明策略评估的收敛性  49
3.3  基于gym的编程实例  52
3.4  *优控制与强化学习比较  54
3.5  习题  56
第二篇  基于值函数的强化学习方法  57
4  基于蒙特卡罗的强化学习方法  58
4.1  基于蒙特卡罗方法的理论  58
4.2  统计学基础知识  67
4.3  基于Python的编程实例  71
4.4  习题  74
5  基于时间差分的强化学习方法  75
5.1  基于时间差分强化学习算法理论讲解  75
5.2  基于Python和gym的编程实例  83
5.3  习题  87
6  基于值函数逼近的强化学习方法  88
6.1  基于值函数逼近的理论讲解  88
6.2  DQN及其变种  94
6.2.1  DQN方法  94
6.2.2  Double DQN  100
6.2.3  优先回放（Prioritized Replay）  102
6.2.4  Dueling DQN  104
6.3  函数逼近方法  105
6.3.1  基于非参数的函数逼近  105
6.3.2  基于参数的函数逼近  111
6.3.3  卷积神经网络  117
6.4  习题  123
第三篇  基于直接策略搜索的强化学习方法  125
7  基于策略梯度的强化学习方法  126
7.1  基于策略梯度的强化学习方法理论讲解  126
7.2  基于gym和TensorFlow的策略梯度算法实现  134
7.2.1  安装Tensorflow  135
7.2.2  策略梯度算法理论基础  135
7.2.3  Softmax策略及其损失函数  136
7.2.4  基于TensorFlow的策略梯度算法实现  138
7.2.5  基于策略梯度算法的小车倒立摆问题  141
7.3  习题  141
8  基于置信域策略优化的强化学习方法  142
8.1  理论基础  143
8.2  TRPO中的数学知识  153
8.2.1  信息论  153
8.2.2  优化方法  155
8.3  习题  164
9  基于确定性策略搜索的强化学习方法  165
9.1  理论基础  165
9.2  习题  170
10  基于引导策略搜索的强化学习方法  171
10.1  理论基础  171
10.2  GPS中涉及的数学基础  178
10.2.1  监督相LBFGS优化方法  178
10.2.2  ADMM算法  179
10.2.3  KL散度与变分推理  183
10.3  习题  184
第四篇  强化学习研究及前沿  185
11  逆向强化学习  186
11.1  概述  186
11.2  基于*大边际的逆向强化学习  187
11.3  基于*大熵的逆向强化学习  194
11.4  习题  201
12  组合策略梯度和值函数方法  202
13  值迭代网络  207
13.1  为什么要提出值迭代网络  207
13.2  值迭代网络  210
14  基于模型的强化学习方法：PILCO及其扩展  214
14.1  概述  214
14.2  PILCO  216
14.3  滤波PILCO和探索PILCO  226
14.3.1  滤波PILCO算法  227
14.3.2  有向探索PILCO算法  230
14.4  深度PILCO  232
后记  235
参考文献  237
