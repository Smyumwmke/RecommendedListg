深入浅出GAN生成对抗网络 原理剖析与TensorFlow实践 PDF下载 廖茂文潘志宏 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711551795
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711551795
<p>书名:深入浅出GAN生成对抗网络 原理剖析与TensorFlow实践</p><p>作者:廖茂文 潘志宏</p><p>页数:480</p><p>定价:¥99.0</p><p>出版社:人民邮电出版社</p><p>出版日期:2020-06-01</p><p>ISBN:9787115517951</p><p><h2>本书特色</h2></p>[<p>
本书首先从Python 基本语法开始讨论，逐步介绍**的数学知识与神经网络的基本知识，并利用讨论的内容编写一个深度学习框架TensorPy，有了这些知识作为铺垫后，就开始讨论生成对抗网络（GAN）相关的内容。然后，本书使用比较简单的语言来描述GAN 涉及的思想、模型与数学原理，接着便通过TensorFlow实现传统的GAN，并讨论为何一定需要生成器或判别器。接下来，重点介绍GAN 各种常见的变体，包括卷积生成对抗网络、条件对抗生成网络、循环一致性、改进生成对抗网络、渐近增强式生成对抗网络等内容。 本书从模型与数学的角度来理解GAN 变体，希望通过数学符号表达出不同GAN 变体的核心思想，适合人工智能、机器学习、计算机视觉相关专业的人员学习使用。
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书首先从Python 基本语法开始讨论，逐步介绍推荐的数学知识与神经网络的基本知识，并利用讨论的内容编写一个深度学习框架TensorPy，有了这些知识作为铺垫后，就开始讨论生成对抗网络（GAN）相关的内容。然后，本书使用比较简单的语言来描述GAN 涉及的思想、模型与数学原理，接着便通过TensorFlow实现传统的GAN，并讨论为何一定需要生成器或判别器。接下来，重点介绍GAN 各种常见的变体，包括卷积生成对抗网络、条件对抗生成网络、循环一致性、改进生成对抗网络、渐近增强式生成对抗网络等内容。
本书从模型与数学的角度来理解GAN 变体，希望通过数学符号表达出不同GAN 变体的核心思想，适合人工智能、机器学习、计算机视觉相关专业的人员学习使用。</p>]<p><h2>作者简介</h2></p>[<p>廖茂文：游戏AI研究员、高级工程师、中国人工智能学会高级会员。研究兴趣为自然语言处理、生成对抗网络、游戏AI，曾参与多项机器学习项目。 潘志宏：高级工程师，中山大学新华学院“百名骨干教师”，中国人工智能学会高级会员、中国计算机学会会员。研究兴趣为机器学习、深度学习、物联网。主持和参与省市级、校级项目10余项，其中主持广东省普通高校青年创新人才项目、教育部产学合作协同育人项目各一项。发表论文18篇，其中SCI、EI、北大核心期刊12篇，第一作者论文获得北大核心期刊优秀论文、东莞市计算机学会优秀论文。申请发明专利、实用新型专利共8项，其中已授权3项，获得软件著作权3项，已出版教材3部。指导学生获得国家级和省级竞赛奖项50余项，多次获得国家级和省级优秀指导教师奖。</p>]<p><h2>目录</h2></p>
    第 1 章 优雅Python 11.1　Anaconda　11.2　Python 基础　41.2.1　常用数据类型　51.2.2　流程控制　71.2.3　函数定义　81.3　Python 进阶　81.3.1　生成式　91.3.2　可迭代对象与迭代器　91.3.3　生成器　111.3.4　装饰器　111.4　小结　13第　2 章 优雅的数学　142.1　向量与矩阵　142.1.1　向量的概念　142.1.2　向量的基本运算　152.1.3　矩阵的概念　172.1.4　矩阵的运算　192.2　微积分　242.2.1　圆的面积　242.2.2　古典微积分　252.2.3　重建微积分　282.2.4　常用的公式　292.2.5　偏导数　312.2.6　方向导数　312.2.7　链式法则　332.3　概率论　342.3.1　随机变量　342.3.2　条件概率　362.3.3　贝叶斯定理　382.3.4　常见的概率分布　392.4　信息论　412.4.1　信息熵　412.4.2　条件熵　432.4.3　互信息　432.4.4　相对熵（KL 散度）　442.4.5　交叉熵　452.5　小结　46第3　章 初识神经网络　473.1　什么是神经网络　473.1.1　神经网络的历史　473.1.2　神经网络的优势　543.2　神经网络中常见的概念　553.2.1　前向传播算法　553.2.2　损失函数　573.2.3　梯度下降算法　583.2.4　各种梯度下降算法　633.2.5　反向传播算法　673.2.6　过拟合与欠拟合　703.3　动手实现深度学习框架TensorPy　713.3.1　实现计算图　713.3.2　实现Session 对象　743.3.3　实现感知器前向传播算法　763.3.4　实现对数损失　793.3.5　实现梯度下降算法与反向传播算法　813.3.6　实现多层感知器　863.4　TensorFlow 简介　893.4.1　TensorFlow 安装与介绍　893.4.2　TensorFlow 基本概念　903.4.3　TensorFlow 实现多层感知器　913.4.4　TensorBoard 可视化　933.4.5　TensorFlow 模型保存方法　983.5　小结　99第4　章 初识生成对抗网络　1014.1　什么是生成对抗网络　1014.1.1　什么是GAN　1014.1.2　GAN 使用范围　1034.2　GAN 基本原理　1044.2.1　GAN 模型详情　1044.2.2　对抗的本质　1064.3　TensorFlow 实现朴素GAN　1084.3.1　朴素GAN 生成MNIST数据集　1084.3.2　训练与效果展示　1144.4　关于GAN 的几个问题　1174.4.1　为什么生成器G 生成数据需要判别器D 介入　1174.4.2　为什么判别器D 不自己生成数据　1204.4.3　为什么选择GAN　1214.5　小结　122第5　章 生成对抗网络的数学原理　1235.1　拟合真实分布　1235.1.1　*大似然估计　1235.1.2　*大似然估计拟合分布　1255.1.3　*大似然估计与KL散度的关系　1265.2　生成对抗网络　1275.2.1　生成器拟合分布　1275.2.2　判别器计算分布的差异　1285.2.3　GAN 的数学推导　1295.2.4　GAN 的本质　1315.3　统一框架F-GAN　1345.3.1　f 散度　1345.3.2　凸共轭　1375.3.3　f 散度与GAN 之间的关系　1385.4　GAN 训练过程可视化　1395.5　小结　144第6　章 卷积生成对抗网络　1456.1　初识卷积神经网络　1456.1.1　什么是卷积神经网络　1456.1.2　CNN 识别图像过程　1476.1.3　CNN 核心概念　1516.2　TensorFlow 实现卷积网络　1546.2.1　构建CNN 计算图　1546.2.2　训练CNN 网络　1606.2.3　Dropout 操作　1616.2.4　DCGAN：CNN 与GAN有机结合　1626.2.5　Batch Normalization　1646.3　TensorFlow 实现DCGAN 网络　1666.3.1　TensorFlow 实现DCGAN 的生成器 .1676.3.2　TensorFlow 实现DCGAN 的判别器　1706.3.3　获得测试样例　1716.3.4　构建DCGAN 整体　1726.3.5　训练DCGAN　1736.3.6　RussellCould 使用　1796.3.7　结果展示　1856.4　小结　189第7　章 条件对抗生成网络　1907.1　如何实现图像间风格转换　1907.1.1　传统神经网络的缺陷　1907.1.2　普通GAN 的缺陷　1917.2　条件对抗生成网络　1927.2.1　GAN 详解　1927.2.2　CGAN 训练流程　1937.3　ColorGAN 的实现　1947.3.1　生成器与判别器的构建　1947.3.2　图像数据预处理　1977.3.3　ColorGAN 训练学习　2007.3.4　ColorGAN 训练结果　2037.3.5　图像转图像的讨论　2087.4　实现文字转图像　2097.4.1　独热向量　2097.4.2　fashion-mnist 数据集　2107.4.3　FashionCGAN 判别器和生成器　2117.4.4　训练FashionCGAN　2137.5　实现句子转图像　2157.5.1　word2vec 技术　2157.5.2　RNN、LSTM 与GRU　2187.5.3　Skip-Thought Vector　2237.5.4　实现Skip-Thought　2267.5.5　实现句子转图像　2347.6　小结　237第8　章 循环一致性　2388.1　以无监督的方式实现风格转换　2388.2　CycleGAN　2408.2.1　CycleGAN 的架构与目标函数　2418.2.2　CycleGAN 做的改变　2438.2.3　TensorFlow 实现CycleGAN生成器与判别器　2518.2.4　TensorFlow 搭建与训练CycleGAN　2548.2.5　效果展示　2588.3　StarGAN　2628.3.1　StarGAN 的结构与目标函数　2628.3.2　TensorFlow 构建StarGAN模型　2658.3.3　构建StarGAN 的损失　2688.3.4　效果展示　2728.4　语义样式不变的图像跨域转换　2758.4.1　Domain Transfer Network介绍　2768.4.2　DTN 代码结构　2788.4.3　XGAN 介绍　2838.5　小结　287第9　章 改进生成对抗网络　2899.1　传统GAN 存在的问题　2899.1.1　梯度消失　2899.1.2　模式崩溃　2939.2　Wasserstein GAN　2959.2.1　EM 距离　2959.2.2　EM 距离使用在GAN 上　2989.2.3　EM 距离与判别器的关系　2999.2.4　TensorFlow 实现WGAN　3029.3　Improved WGAN（WGAN-GP）　3069.3.1　WGAN 存在的问题　3069.3.2　gradient penalty　3089.3.3　TensorFlow 实现WGAN-GP　3109.4　SN-GAN　3149.4.1　SN-GAN 介绍　3149.4.2　Spectral Normalization方法与SN-GAN　3159.4.3　TensorFlow 实现SNGAN　3219.5　小结　326第　10 章 渐近增强式生成对抗网络　32710.1　堆叠式生成对抗网络StackGAN　32710.1.1　StackGAN-v1　32710.1.2　棋盘效应　33010.1.3　StackGAN-v2　33310.1.4　TensorFlow 实现StackGAN-v2　33510.2　TensorFlow 数据处理　34810.2.1　placeholder 读取数据　34810.2.2　Queue 方式读取数据　34810.2.3　tf.data 读取数据　35310.3　渐近增长生成对抗网络PGGAN .10.3.1　PGGAN 介绍　35510.3.2　PGGAN 的改进点　35610.3.3　TensorFlow 实现PGGAN　36110.4　小结　369第　11 章 GAN 进行特征学习　37011.1　近似推断　37011.1.1　变分推断思想　37111.1.2　平均场　37211.2　InfoGAN　37511.2.1　数据特征与互信息　37611.2.2　InfoGAN 数学原理与模型结构　37711.2.3　TensorFlow 实现InfoGAN　38111.2.4　使用InfoGAN 生成图像　38511.3　VAE-GAN　39011.3.1　AutoEncoder 自编码器　39011.3.2　变分自编码器　39211.3.3　数学角度看VAE　39411.3.4　TensorFlow 实现VAE　40011.3.5　VAE 与GAN 的结合体VAE-GAN　40511.3.6　TensorFlow 实现VAE-GAN　40711.4　小结　414第　12 章 GAN 在NLP 中的运用　41512.1　GAN 在文本生成中遇到的境　41512.2　GAN 生成离散数据的方法　41812.2.1　判别器直接获取生成器的输出　41812.2.2　Gumbel-softmax　42012.3　强化学习简述　42212.3.1　强化学习算法　42312.3.2　Policy Gradient　42412.3.3　GAN RL 作用于文本生成　42812.3　SeqGAN　42912.3.1　SeqGAN 结构与算法　42912.3.2　Highway Network　43212.3.3　SeqGAM 生成器与rollout结构的实现　43412.3.4　SeqGAN 中目标LSTM 与判别器的实现　44512.3.5　SeqGAN 中生成器与判别器预训练　45312.3.6　SeqGAN 对抗训练　45912.4　MaskGAN　46112.4.1　MaskGAN 结构与算法　46112.4.2　TensorFlow 实现MaskGAN 的生成器与判别器　46512.4.3　TensorFlow 实现MaskGAN 的Actor-Critic 与目标函数　47212.4.4　TensorFlow 实现MaskGAN 的结构与训练逻辑　47612.5　小结　480
