深度实践Spark机器学习 PDF下载 吴茂贵 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711158995
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711158995
<p>书名:深度实践Spark机器学习</p><p>作者:吴茂贵</p><p>页数:234页</p><p>定价:¥69.0</p><p>出版社:机械工业出版社</p><p>出版日期:2018-02-01</p><p>ISBN:9787111589952</p><p><h2>本书特色</h2></p>[<p>
本书以新的Spark2.0为技术基础，重点讲解了如何构建机器学习系统以及如何实现机器学习流程的标准化，这两点都是目前同类书中没有的。第1～7章从概念、架构、算法等角度介绍了机器学习的基本概念；第8～12章以实例为主，详细讲解了机器学习流程标准化涉及的关键技术；第13章主要以在线数据或流式数据为主介绍了流式计算框架SparkStreaming；第14章重点讲解了深度学习的框架TensorFlowOnSprak。此外，附录部分提供了线性代数、概率统计及Scala的基础知识，帮助读者更好地学习和掌握机器学习的相关内容。
                                        </p>]<p><h2>目录</h2></p>
    目　　录?Contents前言第1章　了解机器学习  11.1　机器学习的定义  11.2　大数据与机器学习  21.3　机器学习、人工智能及深度学习  21.4　机器学习的基本任务  31.5　如何选择合适算法  41.6　Spark在机器学习方面的优势  51.7　小结  5第2章　构建Spark机器学习系统  62.1　机器学习系统架构  62.2　启动集群  72.3　加载数据  92.4　探索数据  102.4.1　数据统计信息  102.4.2　数据质量分析  112.4.3　数据特征分析  122.4.4　数据的可视化  172.5　数据预处理  192.5.1　数据清理  202.5.2　数据变换  212.5.3　数据集成  222.5.4　数据归约  232.6　构建模型  252.7　模型评估  262.8　组装  302.9　模型选择或调优  302.9.1　交叉验证  312.9.2　训练–验证切分  322.10　保存模型  322.11　小结  33第3章　ML Pipeline原理与实战  343.1　Pipeline简介  343.2　DataFrame  353.3　Pipeline组件  363.4　Pipeline原理  373.5　Pipeline实例  383.5.1　使用Estimator、Transformer和Param的实例  383.5.2　ML使用Pipeline的实例  403.6　小结  41第4章　特征提取、转换和选择  424.1　特征提取  424.1.1　词频—逆向文件频率（TF-IDF）  424.1.2　Word2Vec  434.1.3　计数向量器  444.2　特征转换  454.2.1　分词器  454.2.2　移除停用词  464.2.3　n-gram  474.2.4　二值化  484.2.5　主成分分析  484.2.6　多项式展开  504.2.7　离散余弦变换  504.2.8　字符串—索引变换  514.2.9　 索引—字符串变换  534.2.10　独热编码  544.2.11　向量—索引变换  574.2.12　交互式  584.2.13　正则化  594.2.14　规范化  604.2.15　*大值—*小值缩放  604.2.16　*大值—绝对值缩放  614.2.17　离散化重组  624.2.18　元素乘积  634.2.19　SQL转换器  644.2.20　向量汇编  654.2.21　分位数离散化  664.3　特征选择  674.3.1　向量机  674.3.2　R公式  694.3.3　卡方特征选择  704.4　小结  71第5章　模型选择和优化  725.1　模型选择  725.2　交叉验证  735.3　训练验证拆分法  755.4　自定义模型选择  765.5　小结  78第6章　Spark MLlib基础  796.1　Spark MLlib简介  806.2　Spark MLlib架构  816.3　数据类型  826.4　基础统计  846.4.1　摘要统计  846.4.2　相关性  846.4.3　假设检验  856.4.4　随机数据生成  856.5　RDD、Dataframe和Dataset  866.5.1　RDD  866.5.2　DatasetDataFrame  876.5.3　相互转换  886.6　小结  89第7章　构建Spark ML推荐模型  907.1　推荐模型简介  917.2　数据加载  927.3　数据探索  947.4　训练模型  947.5　组装  957.6　评估模型  967.7　模型优化  967.8　小结  98第8章　构建Spark ML分类模型  998.1　分类模型简介  998.1.1　线性模型  1008.1.2　决策树模型  1018.1.3　朴素贝叶斯模型  1028.2　数据加载  1028.3　数据探索  1038.4　数据预处理  1048.5　组装  1098.6　模型优化  1108.7　小结  113第9章　构建Spark ML回归模型  1149.1　回归模型简介  1159.2　数据加载  1159.3　探索特征分布  1179.4　数据预处理  1209.4.1　特征选择  1219.4.2　特征转换  1219.5　组装  1229.6　模型优化  1249.7　小结  126第10章　构建Spark ML聚类模型  12710.1　K-means模型简介  12810.2　数据加载  12910.3　探索特征的相关性  12910.4　数据预处理  13110.5　组装  13210.6　模型优化  13410.7　小结  136第11章　PySpark 决策树模型  13711.1　PySpark 简介  13811.2　决策树简介  13911.3　数据加载  14011.3.1　原数据集初探  14011.3.2　PySpark的启动  14211.3.3　基本函数  14211.4　数据探索  14311.5　数据预处理  14311.6　创建决策树模型  14511.7　训练模型进行预测  14611.8　模型优化  14911.8.1　特征值的优化  14911.8.2　交叉验证和网格参数  15211.9　脚本方式运行  15411.9.1　在脚本中添加配置信息  15411.9.2　运行脚本程序  15411.10　小结  154第12章　SparkR朴素贝叶斯模型  15512.1　SparkR简介  15612.2　获取数据  15712.2.1　SparkDataFrame数据结构说明  15712.2.2　创建SparkDataFrame  15712.2.3　SparkDataFrame的常用操作  16012.3　朴素贝叶斯分类器  16212.3.1　数据探查  16212.3.2　对原始数据集进行转换  16312.3.3　查看不同船舱的生还率差异  16312.3.4　转换成SparkDataFrame格式的数据  16512.3.5　模型概要  16512.3.6　预测  16512.3.7　评估模型  16612.4　小结  167第13章　使用Spark Streaming构建在线学习模型  16813.1　Spark Streaming简介  16813.1.1　Spark Streaming常用术语  16913.1.2　Spark Streaming处理流程  16913.2　Dstream操作
