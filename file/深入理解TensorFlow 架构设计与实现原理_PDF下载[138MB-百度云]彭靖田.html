深入理解TensorFlow:架构设计与实现原理 PDF下载 彭靖田 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711548094
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711548094
<p>书名:深入理解TensorFlow:架构设计与实现原理</p><p>作者:彭靖田</p><p>页数:354</p><p>定价:¥79.0</p><p>出版社:人民邮电出版社</p><p>出版日期:2018-05-26</p><p>ISBN:9787115480941</p><p><h2>本书特色</h2></p>[<p>
本书以TensorFlow 1.2为基础，从基本概念、内部实现和实践等方面深入剖析了TensorFlow。书中首先介绍了TensorFlow设计目标、基本架构、环境准备和基础概念，接着重点介绍了以数据流图为核心的机器学习编程框架的设计原则与核心实现，紧接着还将TensorFlow与深度学习相结合，从理论基础和程序实现这两个方面系统介绍了CNN、GAN和RNN等经典模型，然后深入剖析了TensorFlow运行时核心、通信原理和数据流图计算的原理与实现，*后全面介绍了TensorFlow生态系统的发展。
                                        </p>]<p><h2>内容简介</h2></p>[<p>才云科技技术总监、华为深度学习团队系统工程师、华为公司深度学习云服务的技术负责人联合编写
才云科技创始人兼CEO张鑫、Google Brain工程师周?h枫、云账户联合创始人兼CTO邹永强、博拉科技创始人兼CEO周公爽、微软亚洲研究院助理研究员王锦鹏、才云科技大数据科学家郑泽宇联合推荐
不仅介绍如何使用TensorFlow，还剖析了系统设计原理，基于TensorFlow 1.2讲解。 </p>]<p><h2>作者简介</h2></p>[<p>彭靖田，才云科技技术总监，谷歌机器学习开发专家（ML GDE），Kubeflow Core Maintainer，TensorFlow Contributor，曾一度成为TensorFlow社区全球前40的贡献者。加州大学圣迭戈分校访问学者，毕业于浙江大学竺可桢学院求是科学班。曾为华为深度学习团队核心成员，主要参与华为深度学习平台的设计和研发工作。
林健，华为深度学习团队系统工程师。在中科院计算所取得博士学位，并在美国俄亥俄州立大学做过博士后研究。长期从事系统软件研发，工作涉及高性能计算与分布式系统，爱好开源软件与人工智能。曾参与开发CNGrid GOS、MVAPICH等工业级软件，并协作创建LingCloud、DataMPI等开源项目。
白小龙，华为公司深度学习云服务的技术负责人，主要负责深度学习平台、模型和算法的研发。长期从事信号、图像处理和机器学习研究，于2015年6月毕业于浙江大学并取得工学博士学位，曾获教育部博士生学术新人奖。</p>]<p><h2>目录</h2></p>
    第 一部分　基础篇
第　1章 TensorFlow系统概述　2
1.1　简介　2
1.1.1　产生背景　2
1.1.2　独特价值　3
1.1.3　版本变迁　4
1.1.4　与其他主流深度学习框架的对比　6
1.2　设计目标　7
1.2.1　灵活通用的深度学习库　8
1.2.2　端云结合的人工智能引擎　9
1.2.3　高性能的基础平台软件　10
1.3　基本架构　12
1.3.1　工作形态　12
1.3.2　组件结构　13
1.4　小结　14
第　2章 TensorFlow环境准备　15
2.1　安装　15
2.1.1　TensorFlow安装概述　15
2.1.2　使用Anaconda安装　17
2.1.3　使用原生pip安装　17
2.1.4　使用virtualenv安装　18
2.1.5　使用Docker安装　19
2.1.6　使用源代码编译安装　20
2.1.7　Hello TensorFlow　22
2.2　依赖项　23
2.2.1　Bazel软件构建工具　24
2.2.2　Protocol Buffers数据结构序列化工具　25
2.2.3　Eigen线性代数计算库　27
2.2.4　CUDA统一计算设备架构　28
2.3　源代码结构　29
2.3.1　根目录　29
2.3.2　tensorflow目录　30
2.3.3　tensorflow/core目录　31
2.3.4　tensorflow/python目录　32
2.3.5　安装目录　33
2.4　小结　33
第3章　TensorFlow基础概念　34
3.1　编程范式：数据流图　34
3.1.1　声明式编程与命令式编程　34
3.1.2　声明式编程在深度学习应用上的优势　35
3.1.3　TensorFlow数据流图的基本概念　38
3.2　数据载体：张量　40
3.2.1　张量：Tensor　40
3.2.2　稀疏张量：SparseTensor　44
3.3　模型载体：操作　46
3.3.1　计算节点：Operation　46
3.3.2　存储节点：Variable　49
3.3.3　数据节点：Placeholder　53
3.4　运行环境：会话　55
3.4.1　普通会话：Session　55
3.4.2　交互式会话：InteractiveSession　59
3.4.3　扩展阅读：会话实现原理　59
3.5　训练工具：优化器　61
3.5.1　损失函数与优化算法　61
3.5.2　优化器概述　64
3.5.3　使用minimize方法训练模型　66
3.5.4　扩展阅读：模型训练方法进阶　68
3.6　一元线性回归模型的*佳实践　72
3.7　小结　76
第二部分　关键模块篇
第4章　TensorFlow数据处理方法　78
4.1　输入数据集　78
4.1.1　使用输入流水线并行读取数据　78
4.1.2　创建批样例数据的方法　86
4.1.3　填充数据节点的方法　87
4.1.4　处理CIFAR-10数据集的*佳实践　88
4.1.5　扩展阅读：MNIST数据集　91
4.2　模型参数　92
4.2.1　模型参数的典型使用流程　92
4.2.2　使用tf.Variable创建、初始化和更新模型参数　92
4.2.3　使用tf.train.Saver保存和恢复模型参数　98
4.2.4　使用变量作用域处理复杂模型　100
4.3　命令行参数　103
4.3.1　使用argparse解析命令行参数　103
4.3.2　使用tf.app.flags解析命令行参数　108
4.4　小结　111
第5章　TensorFlow编程框架　112
5.1　单机程序编程框架　112
5.1.1　概述　112
5.1.2　创建单机数据流图　114
5.1.3　创建并运行单机会话　116
5.2　分布式程序编程框架　118
5.2.1　PS-worker架构概述　118
5.2.2　分布式程序编程框架概述　120
5.2.3　创建TensorFlow集群　121
5.2.4　将操作放置到目标设备　124
5.2.5　数据并行模式　124
5.2.6　同步训练机制　125
5.2.7　异步训练机制　130
5.2.8　使用Supervisor管理模型训练　131
5.2.9　分布式同步训练的*佳实践　133
5.3　小结　137
第6章　TensorBoard可视化工具　138
6.1　概述　138
6.2　可视化数据流图　142
6.2.1　名字作用域与抽象节点　142
6.2.2　可视化数据流图的*佳实践　144
6.2.3　扩展阅读：汇总数据和事件数据　145
6.2.4　扩展阅读：揭秘tf.summary.FileWriter工作原理　147
6.3　可视化学习过程　149
6.3.1　汇总操作概述　149
6.3.2　使用tf.summary.scalar生成折线图　150
6.3.3　使用tf.summary.histogram生成数据分布图　152
6.3.4　使用tf.summary.image生成图像　154
6.3.5　使用tf.summary.audio生成音频　155
6.3.6　可视化MNIST softmax模型学习过程的*佳实践　156
6.4　可视化高维数据　158
6.4.1　使用TensorBoard可视化高维数据　158
6.4.2　可视化MNIST数据集的*佳实践　160
6.5　小结　163
第7章　模型托管工具：TensorFlow Serving　164
7.1　概述　164
7.2　系统架构　165
7.3　安装　167
7.3.1　使用APT安装ModelServer　168
7.3.2　使用源码编译安装ModelServer　169
7.4　*佳实践　170
7.4.1　导出模型　170
7.4.2　发布模型服务　173
7.4.3　更新线上模型服务　174
7.5　小结　175
第三部分　算法模型篇
第8章　深度学习概述　178
8.1　深度学习的历史　178
8.1.1　感知机模型与神经网络　178
8.1.2　神经网络的寒冬与复苏　179
8.1.3　神经网络的发展与第二次寒冬　181
8.1.4　深度学习时代的到来　183
8.2　深度学习的主要应用　184
8.2.1　计算机视觉　185
8.2.2　自然语言处理　186
8.2.3　强化学习　188
8.3　深度学习与TensorFlow　190
8.4　小结　191
第9章　CNN模型　192
9.1　CNN　192
9.1.1　CNN简介　192
9.1.2　卷积层　193
9.1.3　激活层　195
9.1.4　池化层　195
9.1.5　全连接层　196
9.1.6　Dropout层　196
9.1.7　BN层　197
9.1.8　常用的CNN图像分类模型　197
9.2　TensorFlow-Slim　204
9.2.1　TensorFlow-Slim总体结构　204
9.2.2　datasets包和data包　205
9.2.3　preprocessing包　207
9.2.4　deployment包　207
9.2.5　nets包　209
9.2.6　TensorFlow-Slim*佳实践　212
9.3　应用　216
9.3.1　物体检测　216
9.3.2　图像分割　221
9.4　小结　222
第　10章 GAN模型　223
10.1　原理、特点及应用　223
10.1.1　原理　224
10.1.2　特点　225
10.1.3　应用　226
10.2　GAN模型的改进　228
10.2.1　CGAN模型　228
10.2.2　LAPGAN模型　229
10.2.3　DCGAN模型　230
10.2.4　InfoGAN模型　230
10.2.5　LSGAN模型　231
10.2.6　WGAN模型　232
10.3　*佳实践　233
10.4　小结　238
第　11章 RNN模型　239
11.1　基本RNN单元及其变种　239
11.1.1　RNN模型简介　239
11.1.2　基本RNN单元　240
11.1.3　LSTM单元　242
11.1.4　GRU单元　243
11.1.5　双向RNN单元　244
11.1.6　带有其他特性的RNN单元　245
11.2　RNN模型　247
11.2.1　PTB-LSTM语言模型　247
11.2.2　Seq2Seq模型　251
11.3　小结　254
第四部分　核心揭秘篇
第　12章 TensorFlow运行时核心设计与实现　256
12.1　运行时框架概述　256
12.2　关键数据结构　257
12.2.1　张量相关数据结构　258
12.2.2　设备相关数据结构　260
12.2.3　数据流图相关的数据结构　263
12.3　公共基础机制　266
12.3.1　内存分配　266
12.3.2　线程管理　268
12.3.3　多语言接口　269
12.3.4　XLA编译技术　270
12.3.5　单元测试框架　271
12.4　外部环境接口　272
12.4.1　加速器硬件接口　272
12.4.2　系统软件接口　275
12.5　小结　276
第　13章 通信原理与实现　277
13.1　概述　277
13.2　进程内通信　278
13.2.1　通信接口　278
13.2.2　会合点机制　280
13.2.3　异构设备内存访问　282
13.3　进程间通信　283
13.3.1　gRPC通信机制　284
13.3.2　控制通信　286
13.3.3　数据通信　290
13.4　RDMA通信模块　294
13.4.1　模块结构　295
13.4.2　消息语义　296
13.4.3　通信流程　297
13.5　小结　300
第　14章 数据流图计算原理与实现　301
14.1　概述　301
14.2　数据流图创建　302
14.2.1　流程与抽象　303
14.2.2　全图构造　305
14.2.3　子图提取　306
14.2.4　图切分　307
14.2.5　图优化　308
14.3　单机会话运行　308
14.3.1　流程与抽象　309
14.3.2　执行器获取　311
14.3.3　输入数据填充　312
14.3.4　图运行　313
14.3.5　输出数据获取　315
14.3.6　张量保存　315
14.4　分布式会话运行　315
14.4.1　主-从模型　316
14.4.2　主要抽象　317
14.4.3　client创建会话　319
14.4.4　client请求图运行　320
14.4.5　master驱动图运行　321
14.4.6　worker实施图运行　323
14.5　操作节点执行　325
14.5.1　核函数抽象　325
14.5.2　CPU上的执行流程　326
14.5.3　CUDA GPU上的执行流程　326
14.6　小结　327
第五部分　生态发展篇
第　15章 TensorFlow生态环境　330
15.1　生态环境概况　330
15.1.1　社区托管组件　330
15.1.2　第三方项目　333
15.2　深度神经网络库Keras　334
15.2.1　概述　334
15.2.2　模型概述　335
15.2.3　顺序模型　336
15.2.4　函数式模型　338
15.3　TensorFlow与Kubernetes生态的结合　340
15.4　TensorFlow与Spark生态的结合　344
15.5　TensorFlow通信优化技术　345
15.6　TPU及神经网络处理器　348
15.7　NNVM模块化深度学习组件　349
15.8　TensorFlow未来展望——TFX　351
15.9　小结　353
附录A　354

