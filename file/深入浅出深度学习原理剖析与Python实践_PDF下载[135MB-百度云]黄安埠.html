深入浅出深度学习原理剖析与Python实践 PDF下载 黄安埠 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712131270
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712131270
<p>书名:深入浅出深度学习原理剖析与Python实践</p><p>作者:黄安埠</p><p>页数:344</p><p>定价:¥79.0</p><p>出版社:电子工业出版社</p><p>出版日期:2017-06-01</p><p>ISBN:9787121312700</p><p><h2>本书特色</h2></p>[<p>
本书介绍了深度学习相关的原理与应用，全书共分为三大部分，*部分主要回顾了深度学习的发展历史，以及Theano的使用；第二部分详细讲解了与深度学习相关的基础知识，包括线性代数、概率论、概率图模型、机器学习和*化算法；在第三部分中，针对若干核心的深度学习模型，如自编码器、受限玻尔兹曼机、递归神经网络和卷积神经网络等进行详细的原理分析与讲解，并针对不同的模型给出相应的具体应用。本书适合有一定高等数学、机器学习和Python编程基础的在校学生、高校研究者或在企业中从事深度学习的工程师使用，书中对模型的原理与难点进行了深入分析，在每一章的*后都提供了详细的参考文献，读者可以对相关的细节进行更深入的研究。*后，理论与实践相结合，本书针对常用的模型分别给出了相应的应用，读者也可以在Github中下载和查看本书的代码（https://github.com/innovation-cat/DeepLearningBook）。
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书*的特色在于取舍明确，一切无助于迅速理解深度学习精髓的内容全被摒弃了，并着重阐述了技术上的重点和难点；表达上深入浅出：即便是从未接触过AI知识的人，也能从作者简明清晰的表述中，一窥深度学习的殿堂。
对任何一位想成为AI/深度学习领域工程师的读者来说，《深入浅出深度学习：原理剖析与Python实践》能帮你迅速打开AI的大门，并成长为一名合格的AI工程师。
 </p>]<p><h2>作者简介</h2></p>[<p>黄安埠，2012年毕业于清华大学，现为腾讯基础研究高级工程师，目前负责腾讯QQ音乐、全民K歌等产品的个性化推荐研发工作。研究领域包括个性化推荐和自然语言处理，在理论沉淀和工程实践都具有丰富的经验，并撰写了10余项国内相关专利。</p>]<p><h2>目录</h2></p>
    1  绪论	11.1  人工智能、机器学习与深度学习的关系	21.1.1  人工智能——机器推理	31.1.2  机器学习——数据驱动的科学	41.1.3  深度学习——大脑的仿真	71.2  深度学习的发展历程	71.3  深度学习技术概述	91.3.1   从低层到高层的特征抽象	101.3.2  让网络变得更深	121.3.3  自动特征提取	131.4  深度学习框架	142  Theano基础	182.1  符号变量	192.2  符号计算的抽象——符号计算图模型	222.3  函数	252.3.1  函数的定义	252.3.2  Logistic回归	262.3.3   函数的复制	282.4  条件表达式	302.5  循环	312.6  共享变量	382.7  配置	382.7.1  通过THEANO_FLAGS配置	392.7.2  通过.theanorc文件配置	402.8  常用的Debug技巧	412.9  小结	423  线性代数基础	433.1  标量、向量、矩阵和张量	433.2  矩阵初等变换	443.3  线性相关与向量空间	453.4  范数	463.4.1  向量范数	463.4.2  矩阵范数	493.5  特殊的矩阵与向量	523.6  特征值分解	533.7  奇异值分解	553.8  迹运算	563.9  样例：主成分分析	574  概率统计基础	614.1  样本空间与随机变量	624.2  概率分布与分布函数	624.3  一维随机变量	634.3.1  离散随机变量和分布律	634.3.2  连续随机变量和概率密度函数	644.4  多维随机变量	654.4.1  离散型二维随机变量和联合分布律	664.4.2  连续型二维随机变量和联合密度函数	664.5  边缘分布	674.6  条件分布与链式法则	684.6.1   条件概率	684.6.2   链式法则	704.7  多维随机变量的独立性分析	704.7.1  边缘独立	714.7.2  条件独立	714.8  数学期望、方差、协方差	724.8.1  数学期望	724.8.2  方差	734.8.3  协方差	734.8.4  协方差矩阵	754.9  信息论基础	784.9.1  信息熵	784.9.2  条件熵	804.9.3  互信息	814.9.4  交叉熵与相对熵	815  概率图模型	845.1  生成模型与判别模型	865.2  图论基础	875.2.1  图的结构	875.2.2  子图	885.2.3  路径、迹、环与拓扑排序	895.3  贝叶斯网络	935.3.1  因子分解	935.3.2  局部马尔科夫独立性断言	965.3.3  I-Map与因子分解	975.3.4  有效迹	1015.3.5    D-分离与全局马尔科夫独立性	1055.4  马尔科夫网络	1065.4.1  势函数因子与参数化表示	1065.4.2  马尔科夫独立性	1085.5  变量消除	1125.6  信念传播	1135.6.1  聚类图	1135.6.2  团树	1175.6.3  由变量消除构建团树	1215.7  MCMC采样	1245.7.1  随机采样	1245.7.2  随机过程与马尔科夫链	1265.7.3   MCMC采样	1295.7.4   Gibbs采样	1315.8  参数学习	1345.8.1  *大似然估计	1345.8.2  期望*大化算法	1355.9  小结	1376  机器学习基础	1406.1  线性模型	1416.1.1  线性回归	1416.1.2    Logistic回归	1466.1.3  广义的线性模型	1486.2  支持向量机	1496.2.1  *优间隔分类器	1506.2.2  对偶问题	1536.2.3  核函数	1546.3  朴素贝叶斯	1586.4  树模型	1606.4.1  特征选择	1616.4.2  剪枝策略	1636.5  聚类	1646.5.1  距离度量	1656.5.2  层次聚类	1666.5.3   K-means聚类	1696.5.4  谱聚类	1707  数值计算与*优化	1767.1  无约束极小值的*优化条件	1767.2  梯度下降	1787.2.1  传统更新策略	1807.2.2  动量更新策略	1827.2.3  改进的动量更新策略	1837.2.4   自适应梯度策略	1867.3  共轭梯度	1877.4  牛顿法	1917.5  拟牛顿法	1937.5.1  拟牛顿条件	1937.5.2   DFP算法	1947.5.3  BFGS	1957.5.4  L-BFGS	1967.6  约束*优化条件	1998  前馈神经网络	2048.1  生物神经元结构	2058.2  人工神经元结构	2068.3  单层感知机	2078.4  多层感知机	2108.5  激活函数	2148.5.1  激活函数的作用	2158.5.2  常用的激活函数	2179  反向传播与梯度消失	2249.1  经验风险*小化	2259.2  梯度计算	2279.2.1   输出层梯度	2279.2.2    隐藏层梯度	2299.2.3   参数梯度	2339.3  反向传播	2349.4  深度学习训练的难点	2359.4.1  欠拟合——梯度消失	2369.4.2  过拟合	23910  自编码器	24210.1  自编码器	24210.2  降噪自编码器	24410.3  栈式自编码器	24610.4  稀疏编码器	24911  玻尔兹曼机	25511.1  玻尔兹曼机	25511.2  能量模型	25811.2.1  能量函数	25811.2.2  从能量函数到势函数	25911.2.3  从势函数到概率分布	26011.3  推断	26111.3.1  边缘分布	26211.3.2  条件分布	26411.4  学习	26711.4.1   *大似然估计	26811.4.2  对比散度	27111.5  应用：个性化推荐	27311.5.1  个性化推荐概述	27311.5.2  个性化推荐架构与算法	27611.5.3  RBM与协同过滤	28212  递归神经网络	28812.1  Elman递归神经网络	28912.2  时间反向传播	29212.3  长短时记忆网络	29612.4  结构递归神经网络	29912.5  应用：语言模型	30412.5.1  N元统计模型	30512.5.2  基于递归网络的语言模型	309参考文献：	31213  卷积神经网络	31413.1  卷积运算	31513.2  网络结构	31813.3  卷积层	32013.4  池化层	32513.5  应用：文本分类	329
